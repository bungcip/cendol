use crate::{
    intern::StringId,
    source_manager::{SourceId, SourceLoc},
};

// Packed token flags for preprocessor tokens
bitflags::bitflags! {
    #[derive(Clone, Copy, Debug, PartialEq, Eq, Hash)]
    pub struct PPTokenFlags: u8 {
        const LEADING_SPACE = 1 << 0;  // Token has leading whitespace
        const STARTS_PP_LINE = 1 << 1; // Token starts a preprocessing line
        const NEEDS_CLEANUP = 1 << 2;  // Token needs cleanup after expansion
        const MACRO_EXPANDED = 1 << 3; // Token was generated by macro expansion
    }
}

/// Token kinds for preprocessor tokens
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub enum PPTokenKind {
    // Punctuation and operators
    Plus,
    Minus,
    Star,
    Slash,
    Percent, // + - * / %
    And,
    Or,
    Xor,
    Not,
    Tilde, // & | ^ ! ~
    Less,
    Greater,
    LessEqual,
    GreaterEqual,
    Equal,
    NotEqual, // < > <= >= == !=
    LeftShift,
    RightShift, // << >>
    Assign,
    PlusAssign,
    MinusAssign, // = += -=
    StarAssign,
    DivAssign,
    ModAssign, // *= /= %=
    AndAssign,
    OrAssign,
    XorAssign, // &= |= ^=
    LeftShiftAssign,
    RightShiftAssign, // <<= >>=
    Increment,
    Decrement, // ++ --
    Arrow,
    Dot, // -> .
    Question,
    Colon, // ? :
    Comma,
    Semicolon, // , ;
    LeftParen,
    RightParen, // ( )
    LeftBracket,
    RightBracket, // [ ]
    LeftBrace,
    RightBrace, // { }
    Ellipsis,   // ...
    LogicAnd,
    LogicOr, // && ||
    Hash,
    HashHash, // # ##
    // Literals and identifiers
    Identifier(StringId),      // Interned identifier
    StringLiteral(StringId),   // Interned string literal
    CharLiteral(u8, StringId), // byte char value and raw text
    Number(StringId),          // Raw numeric literal text for parser
    // Special
    Eof,
    Eod,
    Unknown,
}

/// Token structure for preprocessor tokens
#[derive(Clone, Copy, Debug)]
pub struct PPToken {
    pub kind: PPTokenKind,
    pub flags: PPTokenFlags,
    pub location: SourceLoc, // Contains file ID and byte offset
    pub length: u16,         // Maximum token length (64KB should be sufficient for any token)
}

impl PPToken {
    /// Create a PPToken with full control over all fields
    pub fn new(kind: PPTokenKind, flags: PPTokenFlags, location: SourceLoc, length: u16) -> Self {
        PPToken {
            kind,
            flags,
            location,
            length,
        }
    }

    /// Create a simple PPToken with empty flags and length 1 (most common case)
    pub fn simple(kind: PPTokenKind, location: SourceLoc) -> Self {
        PPToken::new(kind, PPTokenFlags::empty(), location, 1)
    }

    /// Create a PPToken with text-based length
    pub fn text(kind: PPTokenKind, flags: PPTokenFlags, location: SourceLoc, text: &str) -> Self {
        PPToken::new(kind, flags, location, text.len() as u16)
    }

    /// Create a PPToken with custom flags and length 1
    pub fn with_flags(kind: PPTokenKind, flags: PPTokenFlags, location: SourceLoc) -> Self {
        PPToken::new(kind, flags, location, 1)
    }

    /// Get the raw byte slice from the source buffer for this token
    pub fn get_raw_slice<'a>(&self, buffer: &'a [u8]) -> &'a [u8] {
        let start = self.location.offset() as usize;
        let end = start + self.length as usize;
        &buffer[start..end]
    }

    /// Get the text representation of the token
    pub fn get_text(&self) -> &str {
        match &self.kind {
            PPTokenKind::Identifier(sym) => sym.as_str(),
            PPTokenKind::Number(sym) => sym.as_str(),
            PPTokenKind::StringLiteral(sym) => sym.as_str(),
            PPTokenKind::CharLiteral(_, sym) => sym.as_str(),
            PPTokenKind::LeftParen => "(",
            PPTokenKind::RightParen => ")",
            PPTokenKind::LeftBracket => "[",
            PPTokenKind::RightBracket => "]",
            PPTokenKind::LeftBrace => "{",
            PPTokenKind::RightBrace => "}",
            PPTokenKind::Plus => "+",
            PPTokenKind::Minus => "-",
            PPTokenKind::Star => "*",
            PPTokenKind::Slash => "/",
            PPTokenKind::Percent => "%",
            PPTokenKind::And => "&",
            PPTokenKind::Or => "|",
            PPTokenKind::Xor => "^",
            PPTokenKind::Not => "!",
            PPTokenKind::Tilde => "~",
            PPTokenKind::Less => "<",
            PPTokenKind::Greater => ">",
            PPTokenKind::LessEqual => "<=",
            PPTokenKind::GreaterEqual => ">=",
            PPTokenKind::Equal => "==",
            PPTokenKind::NotEqual => "!=",
            PPTokenKind::LeftShift => "<<",
            PPTokenKind::RightShift => ">>",
            PPTokenKind::Assign => "=",
            PPTokenKind::PlusAssign => "+=",
            PPTokenKind::MinusAssign => "-=",
            PPTokenKind::StarAssign => "*=",
            PPTokenKind::DivAssign => "/=",
            PPTokenKind::ModAssign => "%=",
            PPTokenKind::AndAssign => "&=",
            PPTokenKind::OrAssign => "|=",
            PPTokenKind::XorAssign => "^=",
            PPTokenKind::LeftShiftAssign => "<<=",
            PPTokenKind::RightShiftAssign => ">>=",
            PPTokenKind::Increment => "++",
            PPTokenKind::Decrement => "--",
            PPTokenKind::Arrow => "->",
            PPTokenKind::Dot => ".",
            PPTokenKind::Question => "?",
            PPTokenKind::Colon => ":",
            PPTokenKind::Comma => ",",
            PPTokenKind::Semicolon => ";",
            PPTokenKind::Ellipsis => "...",
            PPTokenKind::LogicAnd => "&&",
            PPTokenKind::LogicOr => "||",
            PPTokenKind::Hash => "#",
            PPTokenKind::HashHash => "##",
            PPTokenKind::Eof => "",
            PPTokenKind::Eod => "",
            PPTokenKind::Unknown => "?",
        }
    }
}

/// Manages lexing from different source buffers
pub(crate) struct PPLexer {
    pub(crate) source_id: SourceId,
    buffer: Vec<u8>,
    pub(crate) position: u32, // its okay to use u32 here since source files are limited to 4 MB
    line_starts: Vec<u32>,
    put_back_token: Option<PPToken>,
    pub(crate) line_offset: u32,
    // pub filename_override: Option<String>,
    pub(crate) in_directive_line: bool, // Whether we are currently processing tokens on a directive line
}

impl PPLexer {
    pub(crate) fn new(source_id: SourceId, buffer: Vec<u8>) -> Self {
        let line_starts = vec![0]; // First line starts at offset 0

        PPLexer {
            source_id,
            buffer,
            position: 0,
            line_starts,
            put_back_token: None,
            line_offset: 0,
            // filename_override: None,
            in_directive_line: false,
        }
    }

    /// Get the next character, handling line splicing transparently
    /// Line splicing: backslash followed by newline removes both characters
    pub(crate) fn next_char(&mut self) -> Option<u8> {
        loop {
            if self.position as usize >= self.buffer.len() {
                return None;
            }

            let mut ch = self.buffer[self.position as usize];
            let mut consumed_len = 1;

            // Phase 1: Trigraphs
            if ch == b'?'
                && (self.position as usize) + 2 < self.buffer.len()
                && self.buffer[self.position as usize + 1] == b'?'
            {
                let replacement = match self.buffer[self.position as usize + 2] {
                    b'=' => Some(b'#'),
                    b'(' => Some(b'['),
                    b'/' => Some(b'\\'),
                    b')' => Some(b']'),
                    b'\'' => Some(b'^'),
                    b'<' => Some(b'{'),
                    b'!' => Some(b'|'),
                    b'>' => Some(b'}'),
                    b'-' => Some(b'~'),
                    _ => None,
                };

                if let Some(r) = replacement {
                    ch = r;
                    consumed_len = 3;
                }
            }

            // Phase 2: Line Splicing
            if ch == b'\\' {
                let next_pos = (self.position as usize) + consumed_len;
                if next_pos < self.buffer.len() {
                    let next_ch = self.buffer[next_pos];
                    if next_ch == b'\n' {
                        // Splicing: \ \n
                        self.position = (next_pos + 1) as u32;
                        self.line_starts.push(self.position);
                        continue;
                    } else if next_ch == b'\r' {
                        // Splicing: \ \r or \ \r \n
                        let after_next = next_pos + 1;
                        if after_next < self.buffer.len() && self.buffer[after_next] == b'\n' {
                            self.position = (after_next + 1) as u32;
                        } else {
                            self.position = (next_pos + 1) as u32;
                        }
                        self.line_starts.push(self.position);
                        continue;
                    }
                }
            }

            self.position += consumed_len as u32;

            // Update line starts for regular newlines
            if ch == b'\n' {
                self.line_starts.push(self.position);
            }

            return Some(ch);
        }
    }

    /// Peek at the next character without consuming it, handling line splicing
    pub(crate) fn peek_char(&mut self) -> Option<u8> {
        let saved_position = self.position;
        let saved_line_starts = self.line_starts.clone();

        let result = self.next_char();

        // Restore state
        self.position = saved_position;
        self.line_starts = saved_line_starts;

        result
    }

    /// âš¡ Bolt: Consolidated operator lexing.
    /// This helper function centralizes the logic for lexing single and multi-character operators,
    /// significantly reducing code duplication and branching in the main `next_token` function.
    /// This improves performance by making the tokenization logic more direct and predictable
    /// for the compiler to optimize. It also fixes a bug in the original `...` lexing logic.
    fn lex_operator(&mut self, start_pos: u32, ch: u8, flags: PPTokenFlags) -> PPToken {
        let loc = SourceLoc::new(self.source_id, start_pos);

        // Helper macro to reduce boilerplate when creating a token.
        macro_rules! token {
            ($kind:expr, $len:expr) => {
                PPToken::new($kind, flags, loc, $len)
            };
        }

        // Helper macro to check the next character and consume it if it matches.
        macro_rules! consume_if {
            ($c:expr) => {{
                if self.peek_char() == Some($c) {
                    self.next_char();
                    true
                } else {
                    false
                }
            }};
        }

        match ch {
            b'+' => {
                if consume_if!(b'+') {
                    token!(PPTokenKind::Increment, 2)
                } else if consume_if!(b'=') {
                    token!(PPTokenKind::PlusAssign, 2)
                } else {
                    token!(PPTokenKind::Plus, 1)
                }
            }
            b'-' => {
                if consume_if!(b'-') {
                    token!(PPTokenKind::Decrement, 2)
                } else if consume_if!(b'=') {
                    token!(PPTokenKind::MinusAssign, 2)
                } else if consume_if!(b'>') {
                    token!(PPTokenKind::Arrow, 2)
                } else {
                    token!(PPTokenKind::Minus, 1)
                }
            }
            b'*' => {
                if consume_if!(b'=') {
                    token!(PPTokenKind::StarAssign, 2)
                } else {
                    token!(PPTokenKind::Star, 1)
                }
            }
            b'/' => {
                if consume_if!(b'=') {
                    token!(PPTokenKind::DivAssign, 2)
                } else {
                    token!(PPTokenKind::Slash, 1)
                }
            }
            b'%' => {
                if consume_if!(b'=') {
                    token!(PPTokenKind::ModAssign, 2)
                } else if consume_if!(b'>') {
                    token!(PPTokenKind::RightBrace, 2)
                } else {
                    token!(PPTokenKind::Percent, 1)
                }
            }
            b'=' => {
                if consume_if!(b'=') {
                    token!(PPTokenKind::Equal, 2)
                } else {
                    token!(PPTokenKind::Assign, 1)
                }
            }
            b'!' => {
                if consume_if!(b'=') {
                    token!(PPTokenKind::NotEqual, 2)
                } else {
                    token!(PPTokenKind::Not, 1)
                }
            }
            b'<' => {
                if consume_if!(b'<') {
                    if consume_if!(b'=') {
                        token!(PPTokenKind::LeftShiftAssign, 3)
                    } else {
                        token!(PPTokenKind::LeftShift, 2)
                    }
                } else if consume_if!(b'=') {
                    token!(PPTokenKind::LessEqual, 2)
                } else if consume_if!(b':') {
                    token!(PPTokenKind::LeftBracket, 2)
                } else if consume_if!(b'%') {
                    token!(PPTokenKind::LeftBrace, 2)
                } else {
                    token!(PPTokenKind::Less, 1)
                }
            }
            b'>' => {
                if consume_if!(b'>') {
                    if consume_if!(b'=') {
                        token!(PPTokenKind::RightShiftAssign, 3)
                    } else {
                        token!(PPTokenKind::RightShift, 2)
                    }
                } else if consume_if!(b'=') {
                    token!(PPTokenKind::GreaterEqual, 2)
                } else {
                    token!(PPTokenKind::Greater, 1)
                }
            }
            b'&' => {
                if consume_if!(b'&') {
                    token!(PPTokenKind::LogicAnd, 2)
                } else if consume_if!(b'=') {
                    token!(PPTokenKind::AndAssign, 2)
                } else {
                    token!(PPTokenKind::And, 1)
                }
            }
            b'|' => {
                if consume_if!(b'|') {
                    token!(PPTokenKind::LogicOr, 2)
                } else if consume_if!(b'=') {
                    token!(PPTokenKind::OrAssign, 2)
                } else {
                    token!(PPTokenKind::Or, 1)
                }
            }
            b'^' => {
                if consume_if!(b'=') {
                    token!(PPTokenKind::XorAssign, 2)
                } else {
                    token!(PPTokenKind::Xor, 1)
                }
            }
            b'~' => token!(PPTokenKind::Tilde, 1),
            b'.' => 'ellipsis: {
                let pos_after_first = self.position;
                if self.peek_char() == Some(b'.') {
                    self.next_char(); // Consume second '.'
                    if self.peek_char() == Some(b'.') {
                        self.next_char(); // Consume third '.'
                        break 'ellipsis token!(PPTokenKind::Ellipsis, 3);
                    }
                    // It was '..', which is not a valid C token. Backtrack to handle it as a single '.'
                    self.position = pos_after_first;
                }
                token!(PPTokenKind::Dot, 1)
            }
            b'?' => token!(PPTokenKind::Question, 1),
            b':' => {
                if consume_if!(b'>') {
                    token!(PPTokenKind::RightBracket, 2)
                } else {
                    token!(PPTokenKind::Colon, 1)
                }
            }
            b',' => token!(PPTokenKind::Comma, 1),
            b';' => token!(PPTokenKind::Semicolon, 1),
            b'(' => token!(PPTokenKind::LeftParen, 1),
            b')' => token!(PPTokenKind::RightParen, 1),
            b'[' => token!(PPTokenKind::LeftBracket, 1),
            b']' => token!(PPTokenKind::RightBracket, 1),
            b'{' => token!(PPTokenKind::LeftBrace, 1),
            b'}' => token!(PPTokenKind::RightBrace, 1),
            _ => token!(PPTokenKind::Unknown, 1),
        }
    }

    pub(crate) fn next_token(&mut self) -> Option<PPToken> {
        if let Some(token) = self.put_back_token.take() {
            return Some(token);
        }

        let saved_position = self.position;
        self.skip_whitespace_and_comments();
        let had_leading_space = self.position > saved_position;

        if self.position as usize >= self.buffer.len() {
            if self.in_directive_line {
                self.in_directive_line = false;
                return Some(PPToken::new(
                    PPTokenKind::Eod,
                    PPTokenFlags::empty(),
                    SourceLoc::new(self.source_id, self.position),
                    0,
                ));
            } else {
                return None;
            }
        }

        let flags = if had_leading_space {
            PPTokenFlags::LEADING_SPACE
        } else {
            PPTokenFlags::empty()
        };

        let start_pos = self.position;
        let ch = self.next_char().unwrap_or(b' ');

        // Check if this is a newline that ends a directive line
        // Only \n triggers Eod, \r is treated as whitespace (Windows \r\n support)
        if ch == b'\n' && self.in_directive_line {
            self.in_directive_line = false;
            return Some(PPToken::new(
                PPTokenKind::Eod,
                flags,
                SourceLoc::new(self.source_id, start_pos),
                1,
            ));
        }

        match ch {
            b'a'..=b'z' | b'A'..=b'Z' | b'_' => {
                if ch == b'L' || ch == b'u' || ch == b'U' {
                    let next_ch = self.peek_char();
                    if next_ch == Some(b'"') {
                        Some(self.lex_string_literal(start_pos, ch, flags))
                    } else if next_ch == Some(b'\'') {
                        Some(self.lex_char_literal(start_pos, ch, flags))
                    } else {
                        Some(self.lex_identifier(start_pos, ch, flags))
                    }
                } else {
                    Some(self.lex_identifier(start_pos, ch, flags))
                }
            }
            b'0'..=b'9' => Some(self.lex_number(start_pos, ch, flags)),
            b'"' => Some(self.lex_string_literal(start_pos, ch, flags)),
            b'\'' => Some(self.lex_char_literal(start_pos, ch, flags)),
            b'#' => {
                let mut token_flags = flags;
                token_flags |= PPTokenFlags::STARTS_PP_LINE;
                if self.peek_char() == Some(b'#') {
                    self.next_char(); // consume the second #
                    Some(PPToken::new(
                        PPTokenKind::HashHash,
                        flags, // HashHash does not start a PP line
                        SourceLoc::new(self.source_id, start_pos),
                        2,
                    ))
                } else {
                    // Set directive line flag when we encounter a # that starts a preprocessor line
                    self.in_directive_line = true;
                    Some(PPToken::with_flags(
                        PPTokenKind::Hash,
                        token_flags,
                        SourceLoc::new(self.source_id, start_pos),
                    ))
                }
            }
            b'%' => {
                if self.peek_char() == Some(b':') {
                    self.next_char(); // consume :
                    // Check for %:%: (##)
                    let saved_pos = self.position;
                    let saved_lines = self.line_starts.clone();

                    if self.peek_char() == Some(b'%') {
                        self.next_char(); // consume %
                        if self.peek_char() == Some(b':') {
                            self.next_char(); // consume :
                            Some(PPToken::new(
                                PPTokenKind::HashHash,
                                flags,
                                SourceLoc::new(self.source_id, start_pos),
                                4,
                            ))
                        } else {
                            // Backtrack
                            self.position = saved_pos;
                            self.line_starts = saved_lines;

                            let mut token_flags = flags;
                            token_flags |= PPTokenFlags::STARTS_PP_LINE;
                            self.in_directive_line = true;
                            Some(PPToken::with_flags(
                                PPTokenKind::Hash,
                                token_flags,
                                SourceLoc::new(self.source_id, start_pos),
                            ))
                        }
                    } else {
                        // %: -> Hash
                        let mut token_flags = flags;
                        token_flags |= PPTokenFlags::STARTS_PP_LINE;
                        self.in_directive_line = true;
                        Some(PPToken::with_flags(
                            PPTokenKind::Hash,
                            token_flags,
                            SourceLoc::new(self.source_id, start_pos),
                        ))
                    }
                } else {
                    Some(self.lex_operator(start_pos, ch, flags))
                }
            }
            // All operators and punctuation are handled by the optimized helper function.
            b'+' | b'-' | b'*' | b'/' | b'=' | b'!' | b'<' | b'>' | b'&' | b'|' | b'^' | b'~' | b'.' | b'?' | b':'
            | b',' | b';' | b'(' | b')' | b'[' | b']' | b'{' | b'}' => Some(self.lex_operator(start_pos, ch, flags)),
            _ => Some(PPToken::new(
                PPTokenKind::Unknown,
                flags,
                SourceLoc::new(self.source_id, start_pos),
                1,
            )),
        }
    }

    fn skip_whitespace_and_comments(&mut self) {
        loop {
            // Skip whitespace, handling line splicing
            // But don't skip newlines if we're in a directive line (let them be processed as tokens)
            while let Some(ch) = self.peek_char() {
                if ch.is_ascii_whitespace() && !(ch == b'\n' && self.in_directive_line) {
                    self.next_char();
                } else {
                    break;
                }
            }

            if self.position as usize >= self.buffer.len() {
                break;
            }

            // Check for comments by temporarily consuming
            let saved_position = self.position;
            let saved_line_starts = self.line_starts.clone();

            let ch1 = self.next_char();
            let ch2 = self.next_char();

            if ch1 == Some(b'/') && ch2 == Some(b'/') {
                // Line comment, skip to end of line
                while let Some(ch) = self.next_char() {
                    if ch == b'\n' {
                        break;
                    }
                }
                // Continue loop
            } else if ch1 == Some(b'/') && ch2 == Some(b'*') {
                // Block comment, skip to */
                while let Some(ch) = self.next_char() {
                    if ch == b'*' && self.peek_char() == Some(b'/') {
                        self.next_char(); // consume '/'
                        break;
                    }
                }
                // Continue loop
            } else {
                // Not a comment, restore position
                self.position = saved_position;
                self.line_starts = saved_line_starts;
                break;
            }
        }
    }

    /// Consumes characters based on a predicate, building a string.
    ///
    /// The predicate receives the current state and the character.
    /// It should return `true` to consume the character, or `false` to stop.
    /// The closure can modify state (e.g., tracking scientific notation 'e').
    fn consume_while<F, S>(&mut self, mut state: S, first_ch: u8, mut pred: F) -> String
    where
        F: FnMut(&mut S, u8) -> bool,
    {
        let mut chars = vec![first_ch];
        while let Some(ch) = self.peek_char() {
            if pred(&mut state, ch) {
                chars.push(self.next_char().unwrap());
            } else {
                break;
            }
        }
        // Safety: We assume the caller only consumes valid UTF-8 characters (identifiers/numbers)
        // or we handle validation later. For identifiers/numbers constructed from ascii, this is safe.
        // Actually, identifiers can contain unicode in some extensions, but here we assume standard handling.
        // PPLexer usually deals with bytes, but text tokens are generally UTF-8 compatible.
        String::from_utf8(chars).unwrap()
    }

    fn lex_identifier(&mut self, start_pos: u32, first_ch: u8, flags: PPTokenFlags) -> PPToken {
        let text = self.consume_while((), first_ch, |_, ch| ch.is_ascii_alphanumeric() || ch == b'_');

        let symbol = StringId::new(&text);
        let kind = PPTokenKind::Identifier(symbol);

        PPToken::text(kind, flags, SourceLoc::new(self.source_id, start_pos), &text)
    }

    fn lex_number(&mut self, start_pos: u32, first_ch: u8, flags: PPTokenFlags) -> PPToken {
        let text = self.consume_while(false, first_ch, |seen_e, ch| {
            if ch.is_ascii_digit() || ch == b'.' || ch.is_ascii_alphabetic() || ch == b'_' {
                if ch == b'e' || ch == b'E' || ch == b'p' || ch == b'P' {
                    *seen_e = true;
                }
                true
            } else if (ch == b'+' || ch == b'-') && *seen_e {
                // Allow + or - after e/E for scientific notation
                *seen_e = false; // Reset so we don't allow multiple +/- immediately
                true
            } else {
                false
            }
        });

        let symbol = StringId::new(&text);

        PPToken::text(
            PPTokenKind::Number(symbol),
            flags,
            SourceLoc::new(self.source_id, start_pos),
            &text,
        )
    }

    fn lex_common_literal_body(&mut self, delimiter: u8, chars: &mut Vec<u8>) {
        while let Some(ch) = self.next_char() {
            chars.push(ch);
            if ch == delimiter {
                break; // End of literal
            } else if ch == b'\\' {
                // Handle escape sequences, including line splicing
                if let Some(next_ch) = self.next_char() {
                    chars.push(next_ch);
                    if next_ch == b'\n' {
                        // This is line splicing within a string - the newline is consumed as part of the escape
                        continue;
                    }
                }
            } else if ch >= 0x80 {
                // Handle UTF-8 multi-byte characters
                if self.is_valid_utf8_start(ch) {
                    // Consume continuation bytes for valid UTF-8 sequences
                    while let Some(continuation_ch) = self.peek_char() {
                        if (0x80..0xC0).contains(&continuation_ch) {
                            chars.push(self.next_char().unwrap());
                        } else {
                            break;
                        }
                    }
                }
            }
        }
    }

    fn lex_string_literal(&mut self, start_pos: u32, first_ch: u8, flags: PPTokenFlags) -> PPToken {
        let has_prefix = first_ch == b'L' || first_ch == b'u' || first_ch == b'U';
        let mut chars = vec![first_ch];

        if has_prefix {
            // consume the "
            let quote = self.next_char().unwrap();
            chars.push(quote);
        }

        self.lex_common_literal_body(b'"', &mut chars);

        let text = String::from_utf8(chars).unwrap();
        let symbol = StringId::new(&text);

        PPToken::text(
            PPTokenKind::StringLiteral(symbol),
            flags,
            SourceLoc::new(self.source_id, start_pos),
            &text,
        )
    }

    /// Check if a byte is a valid start of a UTF-8 sequence
    /// Returns true if this could be the start of a valid UTF-8 sequence
    fn is_valid_utf8_start(&self, byte: u8) -> bool {
        // Valid UTF-8 start bytes:
        // 0x00-0x7F: ASCII (single byte, handled elsewhere)
        // 0xC2-0xF4: Start of multi-byte sequence
        // Invalid starts: 0x80-0xBF (continuation bytes), 0xC0, 0xC1, 0xF5-0xFF
        (0xC2..=0xF4).contains(&byte)
    }

    fn lex_char_literal(&mut self, start_pos: u32, first_ch: u8, flags: PPTokenFlags) -> PPToken {
        let has_prefix = first_ch == b'L' || first_ch == b'u' || first_ch == b'U';
        let mut chars = vec![first_ch];

        if has_prefix {
            // consume the '
            let quote = self.next_char().unwrap();
            chars.push(quote);
        }

        self.lex_common_literal_body(b'\'', &mut chars);

        // Parse character literal content
        let quote_start = if has_prefix { 1 } else { 0 };
        let content_start = quote_start + 1;
        let content_len = chars.len() - content_start - 1; // exclude closing '

        let codepoint = if content_len == 1 {
            chars[content_start]
        } else if content_len == 2 && chars[content_start] == b'\\' {
            // Handle escape sequences
            match chars[content_start + 1] {
                b'0' => 0,                     // null
                b'n' => 10,                    // newline
                b't' => 9,                     // tab
                b'r' => 13,                    // carriage return
                b'\\' => 92,                   // backslash
                b'\'' => 39,                   // single quote
                b'"' => 34,                    // double quote
                _ => chars[content_start + 1], // fallback to the escaped char
            }
        } else {
            0 // placeholder for complex cases (multibyte chars, etc.)
        };

        let text = String::from_utf8(chars).unwrap();
        let symbol = StringId::new(&text);

        PPToken::new(
            PPTokenKind::CharLiteral(codepoint, symbol),
            flags,
            SourceLoc::new(self.source_id, start_pos),
            text.len() as u16,
        )
    }

    pub(crate) fn get_line(&self, offset: u32) -> u32 {
        self.line_starts.partition_point(|&x| x <= offset) as u32 + self.line_offset
    }

    pub(crate) fn get_current_line(&self) -> u32 {
        self.line_starts.len() as u32 + self.line_offset
    }

    pub(crate) fn get_line_starts(&self) -> &Vec<u32> {
        &self.line_starts
    }
}
